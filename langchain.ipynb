{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: langchain in c:\\users\\mibey\\work\\jds\\openai\\openai-env\\lib\\site-packages (0.2.12)\n",
      "Requirement already satisfied: PyYAML>=5.3 in c:\\users\\mibey\\work\\jds\\openai\\openai-env\\lib\\site-packages (from langchain) (6.0.1)\n",
      "Requirement already satisfied: SQLAlchemy<3,>=1.4 in c:\\users\\mibey\\work\\jds\\openai\\openai-env\\lib\\site-packages (from langchain) (2.0.31)\n",
      "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in c:\\users\\mibey\\work\\jds\\openai\\openai-env\\lib\\site-packages (from langchain) (3.10.1)\n",
      "Requirement already satisfied: langchain-core<0.3.0,>=0.2.27 in c:\\users\\mibey\\work\\jds\\openai\\openai-env\\lib\\site-packages (from langchain) (0.2.28)\n",
      "Requirement already satisfied: langchain-text-splitters<0.3.0,>=0.2.0 in c:\\users\\mibey\\work\\jds\\openai\\openai-env\\lib\\site-packages (from langchain) (0.2.2)\n",
      "Requirement already satisfied: langsmith<0.2.0,>=0.1.17 in c:\\users\\mibey\\work\\jds\\openai\\openai-env\\lib\\site-packages (from langchain) (0.1.96)\n",
      "Requirement already satisfied: numpy<2.0.0,>=1.26.0 in c:\\users\\mibey\\work\\jds\\openai\\openai-env\\lib\\site-packages (from langchain) (1.26.4)\n",
      "Requirement already satisfied: pydantic<3,>=1 in c:\\users\\mibey\\work\\jds\\openai\\openai-env\\lib\\site-packages (from langchain) (2.8.2)\n",
      "Requirement already satisfied: requests<3,>=2 in c:\\users\\mibey\\work\\jds\\openai\\openai-env\\lib\\site-packages (from langchain) (2.32.3)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<9.0.0,>=8.1.0 in c:\\users\\mibey\\work\\jds\\openai\\openai-env\\lib\\site-packages (from langchain) (8.5.0)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in c:\\users\\mibey\\work\\jds\\openai\\openai-env\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (2.3.4)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in c:\\users\\mibey\\work\\jds\\openai\\openai-env\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.3.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in c:\\users\\mibey\\work\\jds\\openai\\openai-env\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (24.1.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in c:\\users\\mibey\\work\\jds\\openai\\openai-env\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.4.1)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in c:\\users\\mibey\\work\\jds\\openai\\openai-env\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (6.0.5)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in c:\\users\\mibey\\work\\jds\\openai\\openai-env\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.9.4)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in c:\\users\\mibey\\work\\jds\\openai\\openai-env\\lib\\site-packages (from langchain-core<0.3.0,>=0.2.27->langchain) (1.33)\n",
      "Requirement already satisfied: packaging<25,>=23.2 in c:\\users\\mibey\\work\\jds\\openai\\openai-env\\lib\\site-packages (from langchain-core<0.3.0,>=0.2.27->langchain) (24.1)\n",
      "Requirement already satisfied: typing-extensions>=4.7 in c:\\users\\mibey\\work\\jds\\openai\\openai-env\\lib\\site-packages (from langchain-core<0.3.0,>=0.2.27->langchain) (4.12.2)\n",
      "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in c:\\users\\mibey\\work\\jds\\openai\\openai-env\\lib\\site-packages (from langsmith<0.2.0,>=0.1.17->langchain) (3.10.6)\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in c:\\users\\mibey\\work\\jds\\openai\\openai-env\\lib\\site-packages (from pydantic<3,>=1->langchain) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.20.1 in c:\\users\\mibey\\work\\jds\\openai\\openai-env\\lib\\site-packages (from pydantic<3,>=1->langchain) (2.20.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\mibey\\work\\jds\\openai\\openai-env\\lib\\site-packages (from requests<3,>=2->langchain) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\mibey\\work\\jds\\openai\\openai-env\\lib\\site-packages (from requests<3,>=2->langchain) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\mibey\\work\\jds\\openai\\openai-env\\lib\\site-packages (from requests<3,>=2->langchain) (2.2.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\mibey\\work\\jds\\openai\\openai-env\\lib\\site-packages (from requests<3,>=2->langchain) (2024.7.4)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in c:\\users\\mibey\\work\\jds\\openai\\openai-env\\lib\\site-packages (from SQLAlchemy<3,>=1.4->langchain) (3.0.3)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in c:\\users\\mibey\\work\\jds\\openai\\openai-env\\lib\\site-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.3.0,>=0.2.27->langchain) (3.0.0)\n",
      "Requirement already satisfied: openai in c:\\users\\mibey\\work\\jds\\openai\\openai-env\\lib\\site-packages (1.38.0)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in c:\\users\\mibey\\work\\jds\\openai\\openai-env\\lib\\site-packages (from openai) (4.4.0)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in c:\\users\\mibey\\work\\jds\\openai\\openai-env\\lib\\site-packages (from openai) (1.9.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in c:\\users\\mibey\\work\\jds\\openai\\openai-env\\lib\\site-packages (from openai) (0.27.0)\n",
      "Requirement already satisfied: pydantic<3,>=1.9.0 in c:\\users\\mibey\\work\\jds\\openai\\openai-env\\lib\\site-packages (from openai) (2.8.2)\n",
      "Requirement already satisfied: sniffio in c:\\users\\mibey\\work\\jds\\openai\\openai-env\\lib\\site-packages (from openai) (1.3.1)\n",
      "Requirement already satisfied: tqdm>4 in c:\\users\\mibey\\work\\jds\\openai\\openai-env\\lib\\site-packages (from openai) (4.66.5)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.7 in c:\\users\\mibey\\work\\jds\\openai\\openai-env\\lib\\site-packages (from openai) (4.12.2)\n",
      "Requirement already satisfied: idna>=2.8 in c:\\users\\mibey\\work\\jds\\openai\\openai-env\\lib\\site-packages (from anyio<5,>=3.5.0->openai) (3.7)\n",
      "Requirement already satisfied: certifi in c:\\users\\mibey\\work\\jds\\openai\\openai-env\\lib\\site-packages (from httpx<1,>=0.23.0->openai) (2024.7.4)\n",
      "Requirement already satisfied: httpcore==1.* in c:\\users\\mibey\\work\\jds\\openai\\openai-env\\lib\\site-packages (from httpx<1,>=0.23.0->openai) (1.0.5)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in c:\\users\\mibey\\work\\jds\\openai\\openai-env\\lib\\site-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai) (0.14.0)\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in c:\\users\\mibey\\work\\jds\\openai\\openai-env\\lib\\site-packages (from pydantic<3,>=1.9.0->openai) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.20.1 in c:\\users\\mibey\\work\\jds\\openai\\openai-env\\lib\\site-packages (from pydantic<3,>=1.9.0->openai) (2.20.1)\n",
      "Requirement already satisfied: colorama in c:\\users\\mibey\\work\\jds\\openai\\openai-env\\lib\\site-packages (from tqdm>4->openai) (0.4.6)\n",
      "Collecting tiktoken\n",
      "  Downloading tiktoken-0.7.0-cp312-cp312-win_amd64.whl.metadata (6.8 kB)\n",
      "Requirement already satisfied: regex>=2022.1.18 in c:\\users\\mibey\\work\\jds\\openai\\openai-env\\lib\\site-packages (from tiktoken) (2024.7.24)\n",
      "Requirement already satisfied: requests>=2.26.0 in c:\\users\\mibey\\work\\jds\\openai\\openai-env\\lib\\site-packages (from tiktoken) (2.32.3)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\mibey\\work\\jds\\openai\\openai-env\\lib\\site-packages (from requests>=2.26.0->tiktoken) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\mibey\\work\\jds\\openai\\openai-env\\lib\\site-packages (from requests>=2.26.0->tiktoken) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\mibey\\work\\jds\\openai\\openai-env\\lib\\site-packages (from requests>=2.26.0->tiktoken) (2.2.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\mibey\\work\\jds\\openai\\openai-env\\lib\\site-packages (from requests>=2.26.0->tiktoken) (2024.7.4)\n",
      "Downloading tiktoken-0.7.0-cp312-cp312-win_amd64.whl (799 kB)\n",
      "   ---------------------------------------- 0.0/799.3 kB ? eta -:--:--\n",
      "   ---------------------------------------- 799.3/799.3 kB 8.7 MB/s eta 0:00:00\n",
      "Installing collected packages: tiktoken\n",
      "Successfully installed tiktoken-0.7.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: Could not find a version that satisfies the requirement faiss-gpu (from versions: none)\n",
      "ERROR: No matching distribution found for faiss-gpu\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting langchain_experimental\n",
      "  Downloading langchain_experimental-0.0.64-py3-none-any.whl.metadata (1.7 kB)\n",
      "Collecting langchain-community<0.3.0,>=0.2.10 (from langchain_experimental)\n",
      "  Downloading langchain_community-0.2.11-py3-none-any.whl.metadata (2.7 kB)\n",
      "Requirement already satisfied: langchain-core<0.3.0,>=0.2.27 in c:\\users\\mibey\\work\\jds\\openai\\openai-env\\lib\\site-packages (from langchain_experimental) (0.2.28)\n",
      "Requirement already satisfied: PyYAML>=5.3 in c:\\users\\mibey\\work\\jds\\openai\\openai-env\\lib\\site-packages (from langchain-community<0.3.0,>=0.2.10->langchain_experimental) (6.0.1)\n",
      "Requirement already satisfied: SQLAlchemy<3,>=1.4 in c:\\users\\mibey\\work\\jds\\openai\\openai-env\\lib\\site-packages (from langchain-community<0.3.0,>=0.2.10->langchain_experimental) (2.0.31)\n",
      "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in c:\\users\\mibey\\work\\jds\\openai\\openai-env\\lib\\site-packages (from langchain-community<0.3.0,>=0.2.10->langchain_experimental) (3.10.1)\n",
      "Requirement already satisfied: dataclasses-json<0.7,>=0.5.7 in c:\\users\\mibey\\work\\jds\\openai\\openai-env\\lib\\site-packages (from langchain-community<0.3.0,>=0.2.10->langchain_experimental) (0.6.7)\n",
      "Requirement already satisfied: langchain<0.3.0,>=0.2.12 in c:\\users\\mibey\\work\\jds\\openai\\openai-env\\lib\\site-packages (from langchain-community<0.3.0,>=0.2.10->langchain_experimental) (0.2.12)\n",
      "Requirement already satisfied: langsmith<0.2.0,>=0.1.0 in c:\\users\\mibey\\work\\jds\\openai\\openai-env\\lib\\site-packages (from langchain-community<0.3.0,>=0.2.10->langchain_experimental) (0.1.96)\n",
      "Requirement already satisfied: numpy<2.0.0,>=1.26.0 in c:\\users\\mibey\\work\\jds\\openai\\openai-env\\lib\\site-packages (from langchain-community<0.3.0,>=0.2.10->langchain_experimental) (1.26.4)\n",
      "Requirement already satisfied: requests<3,>=2 in c:\\users\\mibey\\work\\jds\\openai\\openai-env\\lib\\site-packages (from langchain-community<0.3.0,>=0.2.10->langchain_experimental) (2.32.3)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<9.0.0,>=8.1.0 in c:\\users\\mibey\\work\\jds\\openai\\openai-env\\lib\\site-packages (from langchain-community<0.3.0,>=0.2.10->langchain_experimental) (8.5.0)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in c:\\users\\mibey\\work\\jds\\openai\\openai-env\\lib\\site-packages (from langchain-core<0.3.0,>=0.2.27->langchain_experimental) (1.33)\n",
      "Requirement already satisfied: packaging<25,>=23.2 in c:\\users\\mibey\\work\\jds\\openai\\openai-env\\lib\\site-packages (from langchain-core<0.3.0,>=0.2.27->langchain_experimental) (24.1)\n",
      "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in c:\\users\\mibey\\work\\jds\\openai\\openai-env\\lib\\site-packages (from langchain-core<0.3.0,>=0.2.27->langchain_experimental) (2.8.2)\n",
      "Requirement already satisfied: typing-extensions>=4.7 in c:\\users\\mibey\\work\\jds\\openai\\openai-env\\lib\\site-packages (from langchain-core<0.3.0,>=0.2.27->langchain_experimental) (4.12.2)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in c:\\users\\mibey\\work\\jds\\openai\\openai-env\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community<0.3.0,>=0.2.10->langchain_experimental) (2.3.4)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in c:\\users\\mibey\\work\\jds\\openai\\openai-env\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community<0.3.0,>=0.2.10->langchain_experimental) (1.3.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in c:\\users\\mibey\\work\\jds\\openai\\openai-env\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community<0.3.0,>=0.2.10->langchain_experimental) (24.1.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in c:\\users\\mibey\\work\\jds\\openai\\openai-env\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community<0.3.0,>=0.2.10->langchain_experimental) (1.4.1)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in c:\\users\\mibey\\work\\jds\\openai\\openai-env\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community<0.3.0,>=0.2.10->langchain_experimental) (6.0.5)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in c:\\users\\mibey\\work\\jds\\openai\\openai-env\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community<0.3.0,>=0.2.10->langchain_experimental) (1.9.4)\n",
      "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in c:\\users\\mibey\\work\\jds\\openai\\openai-env\\lib\\site-packages (from dataclasses-json<0.7,>=0.5.7->langchain-community<0.3.0,>=0.2.10->langchain_experimental) (3.21.3)\n",
      "Requirement already satisfied: typing-inspect<1,>=0.4.0 in c:\\users\\mibey\\work\\jds\\openai\\openai-env\\lib\\site-packages (from dataclasses-json<0.7,>=0.5.7->langchain-community<0.3.0,>=0.2.10->langchain_experimental) (0.9.0)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in c:\\users\\mibey\\work\\jds\\openai\\openai-env\\lib\\site-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.3.0,>=0.2.27->langchain_experimental) (3.0.0)\n",
      "Requirement already satisfied: langchain-text-splitters<0.3.0,>=0.2.0 in c:\\users\\mibey\\work\\jds\\openai\\openai-env\\lib\\site-packages (from langchain<0.3.0,>=0.2.12->langchain-community<0.3.0,>=0.2.10->langchain_experimental) (0.2.2)\n",
      "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in c:\\users\\mibey\\work\\jds\\openai\\openai-env\\lib\\site-packages (from langsmith<0.2.0,>=0.1.0->langchain-community<0.3.0,>=0.2.10->langchain_experimental) (3.10.6)\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in c:\\users\\mibey\\work\\jds\\openai\\openai-env\\lib\\site-packages (from pydantic<3.0.0,>=2.7.4->langchain-core<0.3.0,>=0.2.27->langchain_experimental) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.20.1 in c:\\users\\mibey\\work\\jds\\openai\\openai-env\\lib\\site-packages (from pydantic<3.0.0,>=2.7.4->langchain-core<0.3.0,>=0.2.27->langchain_experimental) (2.20.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\mibey\\work\\jds\\openai\\openai-env\\lib\\site-packages (from requests<3,>=2->langchain-community<0.3.0,>=0.2.10->langchain_experimental) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\mibey\\work\\jds\\openai\\openai-env\\lib\\site-packages (from requests<3,>=2->langchain-community<0.3.0,>=0.2.10->langchain_experimental) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\mibey\\work\\jds\\openai\\openai-env\\lib\\site-packages (from requests<3,>=2->langchain-community<0.3.0,>=0.2.10->langchain_experimental) (2.2.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\mibey\\work\\jds\\openai\\openai-env\\lib\\site-packages (from requests<3,>=2->langchain-community<0.3.0,>=0.2.10->langchain_experimental) (2024.7.4)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in c:\\users\\mibey\\work\\jds\\openai\\openai-env\\lib\\site-packages (from SQLAlchemy<3,>=1.4->langchain-community<0.3.0,>=0.2.10->langchain_experimental) (3.0.3)\n",
      "Requirement already satisfied: mypy-extensions>=0.3.0 in c:\\users\\mibey\\work\\jds\\openai\\openai-env\\lib\\site-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain-community<0.3.0,>=0.2.10->langchain_experimental) (1.0.0)\n",
      "Downloading langchain_experimental-0.0.64-py3-none-any.whl (204 kB)\n",
      "Downloading langchain_community-0.2.11-py3-none-any.whl (2.3 MB)\n",
      "   ---------------------------------------- 0.0/2.3 MB ? eta -:--:--\n",
      "   ---------------------------------------- 2.3/2.3 MB 18.5 MB/s eta 0:00:00\n",
      "Installing collected packages: langchain-community, langchain_experimental\n",
      "Successfully installed langchain-community-0.2.11 langchain_experimental-0.0.64\n",
      "Requirement already satisfied: langchain[docarray] in c:\\users\\mibey\\work\\jds\\openai\\openai-env\\lib\\site-packages (0.2.12)\n",
      "Requirement already satisfied: PyYAML>=5.3 in c:\\users\\mibey\\work\\jds\\openai\\openai-env\\lib\\site-packages (from langchain[docarray]) (6.0.1)\n",
      "Requirement already satisfied: SQLAlchemy<3,>=1.4 in c:\\users\\mibey\\work\\jds\\openai\\openai-env\\lib\\site-packages (from langchain[docarray]) (2.0.31)\n",
      "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in c:\\users\\mibey\\work\\jds\\openai\\openai-env\\lib\\site-packages (from langchain[docarray]) (3.10.1)\n",
      "Requirement already satisfied: langchain-core<0.3.0,>=0.2.27 in c:\\users\\mibey\\work\\jds\\openai\\openai-env\\lib\\site-packages (from langchain[docarray]) (0.2.28)\n",
      "Requirement already satisfied: langchain-text-splitters<0.3.0,>=0.2.0 in c:\\users\\mibey\\work\\jds\\openai\\openai-env\\lib\\site-packages (from langchain[docarray]) (0.2.2)\n",
      "Requirement already satisfied: langsmith<0.2.0,>=0.1.17 in c:\\users\\mibey\\work\\jds\\openai\\openai-env\\lib\\site-packages (from langchain[docarray]) (0.1.96)\n",
      "Requirement already satisfied: numpy<2.0.0,>=1.26.0 in c:\\users\\mibey\\work\\jds\\openai\\openai-env\\lib\\site-packages (from langchain[docarray]) (1.26.4)\n",
      "Requirement already satisfied: pydantic<3,>=1 in c:\\users\\mibey\\work\\jds\\openai\\openai-env\\lib\\site-packages (from langchain[docarray]) (2.8.2)\n",
      "Requirement already satisfied: requests<3,>=2 in c:\\users\\mibey\\work\\jds\\openai\\openai-env\\lib\\site-packages (from langchain[docarray]) (2.32.3)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<9.0.0,>=8.1.0 in c:\\users\\mibey\\work\\jds\\openai\\openai-env\\lib\\site-packages (from langchain[docarray]) (8.5.0)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in c:\\users\\mibey\\work\\jds\\openai\\openai-env\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain[docarray]) (2.3.4)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in c:\\users\\mibey\\work\\jds\\openai\\openai-env\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain[docarray]) (1.3.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in c:\\users\\mibey\\work\\jds\\openai\\openai-env\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain[docarray]) (24.1.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in c:\\users\\mibey\\work\\jds\\openai\\openai-env\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain[docarray]) (1.4.1)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in c:\\users\\mibey\\work\\jds\\openai\\openai-env\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain[docarray]) (6.0.5)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in c:\\users\\mibey\\work\\jds\\openai\\openai-env\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain[docarray]) (1.9.4)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in c:\\users\\mibey\\work\\jds\\openai\\openai-env\\lib\\site-packages (from langchain-core<0.3.0,>=0.2.27->langchain[docarray]) (1.33)\n",
      "Requirement already satisfied: packaging<25,>=23.2 in c:\\users\\mibey\\work\\jds\\openai\\openai-env\\lib\\site-packages (from langchain-core<0.3.0,>=0.2.27->langchain[docarray]) (24.1)\n",
      "Requirement already satisfied: typing-extensions>=4.7 in c:\\users\\mibey\\work\\jds\\openai\\openai-env\\lib\\site-packages (from langchain-core<0.3.0,>=0.2.27->langchain[docarray]) (4.12.2)\n",
      "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in c:\\users\\mibey\\work\\jds\\openai\\openai-env\\lib\\site-packages (from langsmith<0.2.0,>=0.1.17->langchain[docarray]) (3.10.6)\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in c:\\users\\mibey\\work\\jds\\openai\\openai-env\\lib\\site-packages (from pydantic<3,>=1->langchain[docarray]) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.20.1 in c:\\users\\mibey\\work\\jds\\openai\\openai-env\\lib\\site-packages (from pydantic<3,>=1->langchain[docarray]) (2.20.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\mibey\\work\\jds\\openai\\openai-env\\lib\\site-packages (from requests<3,>=2->langchain[docarray]) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\mibey\\work\\jds\\openai\\openai-env\\lib\\site-packages (from requests<3,>=2->langchain[docarray]) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\mibey\\work\\jds\\openai\\openai-env\\lib\\site-packages (from requests<3,>=2->langchain[docarray]) (2.2.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\mibey\\work\\jds\\openai\\openai-env\\lib\\site-packages (from requests<3,>=2->langchain[docarray]) (2024.7.4)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in c:\\users\\mibey\\work\\jds\\openai\\openai-env\\lib\\site-packages (from SQLAlchemy<3,>=1.4->langchain[docarray]) (3.0.3)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in c:\\users\\mibey\\work\\jds\\openai\\openai-env\\lib\\site-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.3.0,>=0.2.27->langchain[docarray]) (3.0.0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: langchain 0.2.12 does not provide the extra 'docarray'\n"
     ]
    }
   ],
   "source": [
    "!pip install langchain\n",
    "!pip install openai\n",
    "!pip install tiktoken\n",
    "!pip install faiss-gpu\n",
    "!pip install langchain_experimental\n",
    "!pip install \"langchain[docarray]\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Document(metadata={'source': 'scalexi.txt'}, page_content=\"ScaleX Innovation Bio\\n\\nScaleX Innovation is a pioneering leader in the realm of Generative AI and Large Language Models. With a keen focus on integrating these transformative technologies into business strategies, the company has carved a niche for itself by offering tailored solutions that enhance innovation and operational efficiency. ScaleX's proficiency extends across multiple industry verticals, ensuring that businesses can harness the power of AI-driven digital transformation. Whether it's automating workflows, content analysis, or custom model implementations, ScaleX Innovation stands at the cutting-edge, committed to bridging the gap between technology and business. Their dedication to ethical compliance and versatility makes them a trusted partner for businesses worldwide.س\\n\\n\\n\\nUnlock the Potential of Generative AI\\nTransform Business With Generative AI\\nScaleX Innovation specializes in Generative AI and Large Language Models, offering bespoke solutions that drive innovation, automate workflows, and enable unprecedented efficiencies for your business.\\n\\n \\nShapeImage\\nScaleX Innovation Image\\nAbout ScaleX Innovation\\nLeaders in Generative AI & Language Models\\nScaleX Innovation is your go-to partner for integrating Generative AI and Large Language Models into your business strategy, unlocking new dimensions of efficiency and innovation.\\n\\nSpecialization in Generative AI Solutions\\nCustom Large Language Model Implementations\\nAI-Enabled Content & Data Analysis\\nExpertise Across Multiple Industry Verticals\\nCommitted to empowering businesses with cutting-edge Generative AI technologies, ScaleX Innovation is redefining what's possible in digital transformation.\\n\\nOur Expertise in Generative AI\\nOur Specialized Services\\nScaleX Innovation is at the forefront of digital transformation, specializing in Generative AI and Large Language Models.\\n\\n\\nWhy Partner With Us?\\nYour Trusted Partners For Digital Transformation\\nAt ScaleX Innovation, we bridge the gap between technology and business, ensuring optimal integration of emerging technologies.\\n\\nCross-Domain Consultation Business Automation Client-Centric Approach\\nIndustry-Agnostic Expertise\\nUniversal Applicability of Generative AI\\nAt ScaleX Innovation, we specialize in applying Generative AI and Large Language Models across a multitude of industries, offering transformative solutions that adapt to specific sector needs.\\n\\n01\\nAdaptive AI Solutions\\nOur Generative AI algorithms are designed to be versatile, scaling and adapting to diverse industrial requirements and challenges.\\n\\n02\\nRegulatory and Ethical Compliance\\nWe ensure our AI-driven solutions adhere to industry regulations and ethical standards, making the transition smooth and reliable.\\n\\n03\\nCross-Sector Innovation\\nWe apply Generative AI to fuel innovation in various business functions, from customer engagement and product development to operations and governance.\\n\\nTech Integration Image\\nContact\\nGET IN TOUCH\\nConnect with ScaleX Innovation. We're here to assist you.\\n\\nAddress:\\nPavillon d’Or Bldg, Route Mahdia Km 0.5, 3000 Sfax, Tunisia.\\nEmail Address:\\ninfo@scalexi.ai\\nPhone Number:\\n++216-55-770-606\\nFax:\\n+216-55-770-606\\nConnect With Us\\nInterested in Our Services?\\nReach out to ScaleX Innovation. We're here to guide you through the future of emerging technologies.\\n\\nName *\\nEmail*\\nNumber*\\nSubject*\\nYour Message*\\n\\nSubmit Inquiry \\nExploring Generative AI with ScaleX Innovation\\nDiscovering the Magic of Generative AI and LLMs on our Medium Blogs\\nAt ScaleX Innovation, we make the complex world of AI easy to understand. We connect the latest tech with real-world business uses. Explore our articles and keep up with the fast-changing world of AI. Check out our Medium page\\n\\nImage\\nBy ScaleXI Fri, 13 Oct 2023 18:39:19 GMT\\nIntroduction to Diffusion Models (Part III. Diffusion Process)\\nImage\\nBy ScaleXI Fri, 13 Oct 2023 17:10:19 GMT\\nIntroduction to Diffusion Models (Part II: Math Intuitions)\\nImage\\nBy ScaleXI Fri, 13 Oct 2023 15:15:00 GMT\\nIntroduction to Diffusion Models (Part I: Basic Concepts)\\n\\nScaleX Innovation Logo\\nScaleX Innovation is at the forefront of integrating AI and emerging technologies into business solutions, driving growth and transformation.\\n\\nConnect With Us    \\nContact Information\\nReach Out on WhatsApp\\n\\n+216-55-770-606\\nEmail Us At\\n\\ninfo@scalexi.ai\\nOur Headquarter\\n\\nRoute Mahdia km 0.5, Pavillon d’Or Building, 3000 Sfax, Tunisia.\\nQuick Links\\nAbout ScaleX\\nOur Services\\nAbout ScaleX Innovation\\nAt ScaleX Innovation, we bridge the gap between technology and business, propelling enterprises into the future with tailored digital solutions.\")]\n"
     ]
    }
   ],
   "source": [
    "from langchain.document_loaders import TextLoader\n",
    "txt_file_path = 'scalexi.txt'\n",
    "loader = TextLoader(file_path=txt_file_path, encoding=\"utf-8\")\n",
    "data = loader.load()\n",
    "print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Document(metadata={'source': 'scalexi.txt'}, page_content=\"ScaleX Innovation Bio\\n\\nScaleX Innovation is a pioneering leader in the realm of Generative AI and Large Language Models. With a keen focus on integrating these transformative technologies into business strategies, the company has carved a niche for itself by offering tailored solutions that enhance innovation and operational efficiency. ScaleX's proficiency extends across multiple industry verticals, ensuring that businesses can harness the power of AI-driven digital transformation. Whether it's automating workflows, content analysis, or custom model implementations, ScaleX Innovation stands at the cutting-edge, committed to bridging the gap between technology and business. Their dedication to ethical compliance and versatility makes them a trusted partner for businesses worldwide.س\"), Document(metadata={'source': 'scalexi.txt'}, page_content=\"Unlock the Potential of Generative AI\\nTransform Business With Generative AI\\nScaleX Innovation specializes in Generative AI and Large Language Models, offering bespoke solutions that drive innovation, automate workflows, and enable unprecedented efficiencies for your business.\\n\\n \\nShapeImage\\nScaleX Innovation Image\\nAbout ScaleX Innovation\\nLeaders in Generative AI & Language Models\\nScaleX Innovation is your go-to partner for integrating Generative AI and Large Language Models into your business strategy, unlocking new dimensions of efficiency and innovation.\\n\\nSpecialization in Generative AI Solutions\\nCustom Large Language Model Implementations\\nAI-Enabled Content & Data Analysis\\nExpertise Across Multiple Industry Verticals\\nCommitted to empowering businesses with cutting-edge Generative AI technologies, ScaleX Innovation is redefining what's possible in digital transformation.\"), Document(metadata={'source': 'scalexi.txt'}, page_content='Our Expertise in Generative AI\\nOur Specialized Services\\nScaleX Innovation is at the forefront of digital transformation, specializing in Generative AI and Large Language Models.\\n\\n\\nWhy Partner With Us?\\nYour Trusted Partners For Digital Transformation\\nAt ScaleX Innovation, we bridge the gap between technology and business, ensuring optimal integration of emerging technologies.\\n\\nCross-Domain Consultation Business Automation Client-Centric Approach\\nIndustry-Agnostic Expertise\\nUniversal Applicability of Generative AI\\nAt ScaleX Innovation, we specialize in applying Generative AI and Large Language Models across a multitude of industries, offering transformative solutions that adapt to specific sector needs.\\n\\n01\\nAdaptive AI Solutions\\nOur Generative AI algorithms are designed to be versatile, scaling and adapting to diverse industrial requirements and challenges.'), Document(metadata={'source': 'scalexi.txt'}, page_content=\"01\\nAdaptive AI Solutions\\nOur Generative AI algorithms are designed to be versatile, scaling and adapting to diverse industrial requirements and challenges.\\n\\n02\\nRegulatory and Ethical Compliance\\nWe ensure our AI-driven solutions adhere to industry regulations and ethical standards, making the transition smooth and reliable.\\n\\n03\\nCross-Sector Innovation\\nWe apply Generative AI to fuel innovation in various business functions, from customer engagement and product development to operations and governance.\\n\\nTech Integration Image\\nContact\\nGET IN TOUCH\\nConnect with ScaleX Innovation. We're here to assist you.\\n\\nAddress:\\nPavillon d’Or Bldg, Route Mahdia Km 0.5, 3000 Sfax, Tunisia.\\nEmail Address:\\ninfo@scalexi.ai\\nPhone Number:\\n++216-55-770-606\\nFax:\\n+216-55-770-606\\nConnect With Us\\nInterested in Our Services?\\nReach out to ScaleX Innovation. We're here to guide you through the future of emerging technologies.\\n\\nName *\\nEmail*\\nNumber*\\nSubject*\\nYour Message*\"), Document(metadata={'source': 'scalexi.txt'}, page_content='Name *\\nEmail*\\nNumber*\\nSubject*\\nYour Message*\\n\\nSubmit Inquiry \\nExploring Generative AI with ScaleX Innovation\\nDiscovering the Magic of Generative AI and LLMs on our Medium Blogs\\nAt ScaleX Innovation, we make the complex world of AI easy to understand. We connect the latest tech with real-world business uses. Explore our articles and keep up with the fast-changing world of AI. Check out our Medium page\\n\\nImage\\nBy ScaleXI Fri, 13 Oct 2023 18:39:19 GMT\\nIntroduction to Diffusion Models (Part III. Diffusion Process)\\nImage\\nBy ScaleXI Fri, 13 Oct 2023 17:10:19 GMT\\nIntroduction to Diffusion Models (Part II: Math Intuitions)\\nImage\\nBy ScaleXI Fri, 13 Oct 2023 15:15:00 GMT\\nIntroduction to Diffusion Models (Part I: Basic Concepts)\\n\\nScaleX Innovation Logo\\nScaleX Innovation is at the forefront of integrating AI and emerging technologies into business solutions, driving growth and transformation.\\n\\nConnect With Us    \\nContact Information\\nReach Out on WhatsApp\\n\\n+216-55-770-606\\nEmail Us At'), Document(metadata={'source': 'scalexi.txt'}, page_content='Connect With Us    \\nContact Information\\nReach Out on WhatsApp\\n\\n+216-55-770-606\\nEmail Us At\\n\\ninfo@scalexi.ai\\nOur Headquarter\\n\\nRoute Mahdia km 0.5, Pavillon d’Or Building, 3000 Sfax, Tunisia.\\nQuick Links\\nAbout ScaleX\\nOur Services\\nAbout ScaleX Innovation\\nAt ScaleX Innovation, we bridge the gap between technology and business, propelling enterprises into the future with tailored digital solutions.')]\n"
     ]
    }
   ],
   "source": [
    "from langchain.text_splitter import CharacterTextSplitter\n",
    "text_splitter = CharacterTextSplitter(chunk_size=1000, chunk_overlap=200)\n",
    "data = text_splitter.split_documents(data)\n",
    "print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting faiss-cpu\n",
      "  Downloading faiss_cpu-1.8.0.post1-cp312-cp312-win_amd64.whl.metadata (3.8 kB)\n",
      "Requirement already satisfied: numpy<2.0,>=1.0 in c:\\users\\mibey\\work\\jds\\openai\\openai-env\\lib\\site-packages (from faiss-cpu) (1.26.4)\n",
      "Requirement already satisfied: packaging in c:\\users\\mibey\\work\\jds\\openai\\openai-env\\lib\\site-packages (from faiss-cpu) (24.1)\n",
      "Downloading faiss_cpu-1.8.0.post1-cp312-cp312-win_amd64.whl (14.6 MB)\n",
      "   ---------------------------------------- 0.0/14.6 MB ? eta -:--:--\n",
      "   ------- -------------------------------- 2.9/14.6 MB 18.6 MB/s eta 0:00:01\n",
      "   ------------------------- -------------- 9.4/14.6 MB 25.6 MB/s eta 0:00:01\n",
      "   ---------------------------------------  14.4/14.6 MB 25.9 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 14.6/14.6 MB 23.5 MB/s eta 0:00:00\n",
      "Installing collected packages: faiss-cpu\n",
      "Successfully installed faiss-cpu-1.8.0.post1\n"
     ]
    }
   ],
   "source": [
    "!pip install faiss-cpu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\mibey\\Work\\JDS\\OpenAI\\openai-env\\Lib\\site-packages\\langchain_core\\_api\\deprecation.py:139: LangChainDeprecationWarning: The class `OpenAIEmbeddings` was deprecated in LangChain 0.0.9 and will be removed in 0.3.0. An updated version of the class exists in the langchain-openai package and should be used instead. To use it run `pip install -U langchain-openai` and import as `from langchain_openai import OpenAIEmbeddings`.\n",
      "  warn_deprecated(\n"
     ]
    }
   ],
   "source": [
    "from langchain_openai import OpenAIEmbeddings\n",
    "from langchain.vectorstores import FAISS\n",
    "\n",
    "embeddings = OpenAIEmbeddings()\n",
    "\n",
    "# Create a FAISS vector store from documents\n",
    "vectorstore = FAISS.from_documents(data, embedding=embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\mibey\\Work\\JDS\\OpenAI\\openai-env\\Lib\\site-packages\\langchain_core\\_api\\deprecation.py:139: LangChainDeprecationWarning: The class `ChatOpenAI` was deprecated in LangChain 0.0.10 and will be removed in 0.3.0. An updated version of the class exists in the langchain-openai package and should be used instead. To use it run `pip install -U langchain-openai` and import as `from langchain_openai import ChatOpenAI`.\n",
      "  warn_deprecated(\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "# Create a language model instance\n",
    "llm = ChatOpenAI(temperature=0.7, model_name=\"gpt-4o-mini\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.memory import ConversationBufferMemory\n",
    "\n",
    "# Create a memory instance\n",
    "memory = ConversationBufferMemory(memory_key='chat_history', return_messages=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains import ConversationalRetrievalChain\n",
    "conversation_chain = ConversationalRetrievalChain.from_llm(\n",
    "    llm=llm,\n",
    "    chain_type=\"stuff\",\n",
    "    retriever=vectorstore.as_retriever(),\n",
    "    memory=memory\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ScaleX Innovation is a leader in Generative AI and Large Language Models, focusing on integrating these technologies into business strategies to enhance innovation and operational efficiency. The company offers tailored solutions across multiple industries, helping businesses automate workflows, analyze content, and implement custom models. Committed to ethical compliance and versatility, ScaleX Innovation aims to bridge the gap between technology and business, driving digital transformation and empowering organizations with cutting-edge AI technologies.\n"
     ]
    }
   ],
   "source": [
    "# Function to ask a query and get a response\n",
    "def ask_query(conversation_chain, query):\n",
    "    response = conversation_chain({'question': query})\n",
    "    return response['answer']\n",
    "\n",
    "# Example query\n",
    "query = \"give brief summary of scalexi\"\n",
    "\n",
    "# Get the response\n",
    "response = ask_query(conversation_chain, query)\n",
    "\n",
    "# Print the result\n",
    "print(response)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "openai-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
